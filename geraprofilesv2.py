# profile_generator_v3.py

import sqlite3
import numpy as np
import faiss
from faker import Faker
import random
from colorama import init, Fore, Style
from rich.console import Console
from rich.progress import track, Progress, SpinnerColumn, BarColumn, TextColumn, TimeElapsedColumn
from rich.table import Table
from typing import List, Dict, Tuple, Any
import logging
import os
from datetime import datetime
import math # Para clustering

# --- Melhorias Implementadas ---
# 1. Logging Detalhado em Arquivo
# 2. Aumento de 800% nos Dados de Base (Cidades, Jogos, etc.)
# 3. Mapeamento Cidade -> Estado para Consist√™ncia Geogr√°fica
# 4. Descri√ß√µes Significativas (sem texto aleat√≥rio)
# 5. Nomes Consistentes com o Sexo
# 6. Gera√ß√£o de Nome baseada no Sexo
# 7. Estado Derivado Automaticamente da Cidade
# 8. Nome Consistente com Sexo (Refor√ßo)
# 9. Descri√ß√£o Baseada em Dados (Refor√ßo)
# 10. Bancos de Dados Separados (Perfis, Vetores, Embeddings, Clusters)
# 11. Cria√ß√£o de Tabelas Robustas com Chaves Prim√°rias
# 12. Fun√ß√£o Dedicada para Inser√ß√£o de Perfis com Progresso
# 13. Gera√ß√£o de Vetores de Caracter√≠sticas Num√©ricas/Categ√≥ricas
# 14. Gera√ß√£o de Embeddings Simulados (Placeholder para Modelo Real)
# 15. Fun√ß√£o Dedicada para Salvar Vetores e Embeddings com Chave Estrangeira (ID)
# 16. +180 Varia√ß√µes de Palavras-Chave para Descri√ß√µes
# 17. Templates de Descri√ß√£o Variados
# 18. Fun√ß√£o `gerar_descricao_consistente`
# 19. Implementa√ß√£o de Clustering B√°sico (FAISS KMeans)
# 20. Uso Extensivo de Rich Console (Cores, Emojis)
# 21. Uso de Barras de Progresso Detalhadas (Rich Progress)
# 22. Uso de Tabelas Rich para Exibi√ß√£o de Dados
# 23. Emojis para Feedback Visual (‚úÖ, ‚öôÔ∏è, üíæ, üìä, üß©, ‚ö†Ô∏è, ‚ÑπÔ∏è)
# 24. Feedback "Real-time" no Console
# 25. Melhor Estrutura de Pipeline (Passos Claros)
# 26. Error Handling Aprimorado com Try/Except e Logging
# 27. Type Hinting para Clareza
# 28. Vari√°veis e Fun√ß√µes com Nomes Descritivos
# 29. Modulariza√ß√£o do C√≥digo em Fun√ß√µes
# 30. Coment√°rios Explicativos
# 31. Constantes Configur√°veis no Topo
# 32. Valida√ß√£o de Dados B√°sica (Ex: Estado encontrado)
# 33. Docstrings para Fun√ß√µes Principais
# 34. Cria√ß√£o Autom√°tica de Diret√≥rio de Logs
# 35. Nomes de Arquivos de Log com Timestamp
# 36. Uso de `executemany` para Inser√ß√£o em Lote (Otimiza√ß√£o)
# 37. C√°lculo Din√¢mico do N√∫mero de Clusters (Opcional, usando raiz quadrada)
# 38. Armazenamento de Cluster ID no DB de Clusters

# Inicializar Colorama
init(autoreset=True)

# --- Configura√ß√£o de Logging (Melhoria #1, #34, #35) ---
LOG_DIR = "logs_v3"
os.makedirs(LOG_DIR, exist_ok=True)
LOG_FILE = os.path.join(LOG_DIR, f"profile_generator_v3_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
logging.basicConfig(filename=LOG_FILE, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', encoding='utf-8')

console = Console()
logging.info("--- Script Iniciado ---")

# --- Defini√ß√µes Globais e Constantes (Melhoria #31) ---
NUM_PROFILES: int = 20000  # N√∫mero de perfis a gerar
FAKER_LOCALE: str = 'pt_BR'
fake = Faker(FAKER_LOCALE)
DIM_EMBEDDING: int = 64  # Dimens√£o do embedding simulado (Melhoria #14)
DIM_VECTOR: int = 10     # Dimens√£o do vetor de caracter√≠sticas (Ajustado)
NUM_CLUSTERS: int = int(math.sqrt(NUM_PROFILES)) # N√∫mero de clusters (Melhoria #37)

# Nomes dos Bancos de Dados (Melhoria #10)
DB_DIR = "databases_v3"
os.makedirs(DB_DIR, exist_ok=True) # Cria diret√≥rio para DBs
DATABASE_PROFILES: str = os.path.join(DB_DIR, 'perfis_jogadores_v3.db')
DATABASE_VECTORS: str = os.path.join(DB_DIR, 'vetores_perfis_v3.db')
DATABASE_EMBEDDINGS: str = os.path.join(DB_DIR, 'embeddings_perfis_v3.db')
DATABASE_CLUSTERS: str = os.path.join(DB_DIR, 'clusters_perfis_v3.db')

# --- Dados de Base Ampliados (Melhoria #2) ---

# Cidades e Mapeamento Cidade -> Estado (Melhoria #3)
CIDADES_ESTADOS = {
    "S√£o Paulo": "SP", "Rio de Janeiro": "RJ", "Bras√≠lia": "DF", "Salvador": "BA", "Fortaleza": "CE",
    "Belo Horizonte": "MG", "Manaus": "AM", "Curitiba": "PR", "Recife": "PE", "Goi√¢nia": "GO",
    "Porto Alegre": "RS", "Bel√©m": "PA", "Guarulhos": "SP", "Campinas": "SP", "S√£o Lu√≠s": "MA",
    "S√£o Gon√ßalo": "RJ", "Macei√≥": "AL", "Duque de Caxias": "RJ", "Campo Grande": "MS", "Natal": "RN",
    "Teresina": "PI", "S√£o Bernardo do Campo": "SP", "Nova Igua√ßu": "RJ", "Jo√£o Pessoa": "PB", "Santo Andr√©": "SP",
    "Osasco": "SP", "Jaboat√£o dos Guararapes": "PE", "Contagem": "MG", "Sorocaba": "SP", "Uberl√¢ndia": "MG",
    "Ribeir√£o Preto": "SP", "Aparecida de Goi√¢nia": "GO", "Cariacica": "ES", "Feira de Santana": "BA", "Caxias do Sul": "RS",
    "Olinda": "PE", "Joinville": "SC", "Montes Claros": "MG", "Ananindeua": "PA", "Santos": "SP",
    "Campos dos Goytacazes": "RJ", "Mau√°": "SP", "Carapicu√≠ba": "SP", "Serra": "ES", "Betim": "MG",
    "Jundia√≠": "SP", "Niter√≥i": "RJ", "Juiz de Fora": "MG", "Piracicaba": "SP", "Porto Velho": "RO",
    "Canoas": "RS", "Maring√°": "PR", "Mogi das Cruzes": "SP", "Londrina": "PR", "S√£o Vicente": "SP",
    "Foz do Igua√ßu": "PR", "Pelotas": "RS", "Vit√≥ria": "ES", "Taubat√©": "SP", "S√£o Jos√© do Rio Preto": "SP",
    "Ponta Grossa": "PR", "Belford Roxo": "RJ", "Rio Branco": "AC", "Itaquaquecetuba": "SP", "Cubat√£o": "SP",
    "Boa Vista": "RR", "Blumenau": "SC", "Novo Hamburgo": "RS", "Guaruj√°": "SP", "Cascavel": "PR",
    "Petrolina": "PE", "Vit√≥ria da Conquista": "BA", "Paulista": "PE", "Praia Grande": "SP", "Imperatriz": "MA",
    "Viam√£o": "RS", "Cama√ßari": "BA", "Juazeiro do Norte": "CE", "Volta Redonda": "RJ", "Sumar√©": "SP",
    "Sete Lagoas": "MG", "Ipatinga": "MG", "Divin√≥polis": "MG", "Parnamirim": "RN", "Mag√©": "RJ",
    "Sobral": "CE", "Mossor√≥": "RN", "Santa Luzia": "MG", "Pindamonhangaba": "SP", "Rio Grande": "RS",
    "Marab√°": "PA", "Crici√∫ma": "SC", "Santa Maria": "RS", "Barreiras": "BA", "Itabuna": "BA",
    "Luzi√¢nia": "GO", "Gravata√≠": "RS", "Bag√©": "RS", "Lauro de Freitas": "BA", "Te√≥filo Otoni": "MG",
    "Garanhuns": "PE", "Passo Fundo": "RS", "Arapiraca": "AL", "Alagoinhas": "BA", "Francisco Morato": "SP",
    "Franco da Rocha": "SP", "Pinhais": "PR", "Colombo": "PR", "Guarapuava": "PR", "Caucaia": "CE",
    "Barueri": "SP", "Palmas": "TO", "Governador Valadares": "MG", "Parauapebas": "PA", "Santa B√°rbara d'Oeste": "SP",
    "Aragua√≠na": "TO", "Ji-Paran√°": "RO", "Cachoeiro de Itapemirim": "ES", "Timon": "MA", "Maracana√∫": "CE",
    "Dourados": "MS", "Itaja√≠": "SC", "Rio das Ostras": "RJ", "Sim√µes Filho": "BA", "Paranagu√°": "PR",
    "Porto Seguro": "BA", "Linhares": "ES", "Uruguaiana": "RS", "Abaetetuba": "PA", "Itapetininga": "SP",
    "Picos": "PI", "Caxias": "MA", "Bragan√ßa Paulista": "SP", "Tangar√° da Serra": "MT", "V√°rzea Grande": "MT",
    "Itapevi": "SP", "Mar√≠lia": "SP", "Cabo Frio": "RJ", "Macap√°": "AP", # Cariacica ES j√° existe
    "Eun√°polis": "BA", #"Feira de Santana": "BA", "Ilh√©us": "BA", "Itabuna": "BA", "Jequi√©": "BA",
    "Paulo Afonso": "BA", "Teixeira de Freitas": "BA", #"Vit√≥ria da Conquista": "BA", "Arapiraca": "AL",
    "Palmeira dos √çndios": "AL", "Rio Largo": "AL", "Uni√£o dos Palmares": "AL", #"Ananindeua": "PA", "Bel√©m": "PA",
    "Castanhal": "PA", #"Marab√°": "PA", "Parauapebas": "PA",
    "Santar√©m": "PA", #"Timon": "MA",
    "Bacabal": "MA", "Balsas": "MA", #"Caxias": "MA", "Imperatriz": "MA",
    "Pa√ßo do Lumiar": "MA", "S√£o Jos√© de Ribamar": "MA", #"Barreiras": "BA",
    "Brumado": "BA", #"Cama√ßari": "BA", "Eun√°polis": "BA", "Feira de Santana": "BA",
    "Ilh√©us": "BA", #"Itabuna": "BA",
    "Jequi√©": "BA", "Juazeiro": "BA", #"Lauro de Freitas": "BA", "Paulo Afonso": "BA", "Salvador": "BA",
    "Santo Ant√¥nio de Jesus": "BA", "Serrinha": "BA", #"Teixeira de Freitas": "BA",
    "Valen√ßa": "BA", #"Vit√≥ria da Conquista": "BA", "Caucaia": "CE",
    "Crato": "CE", #"Fortaleza": "CE", "Juazeiro do Norte": "CE", "Maracana√∫": "CE", "Sobral": "CE",
    "Aquiraz": "CE", "Canind√©": "CE", "Iguatu": "CE", "Itapipoca": "CE", "Maranguape": "CE",
    "Pacatuba": "CE", "Quixad√°": "CE", #"Cascavel": "PR", "Foz do Igua√ßu": "PR", "Guarapuava": "PR", "Londrina": "PR", "Maring√°": "PR",
    "S√£o Jos√© dos Pinhais": "PR", "Umuarama": "PR", "Vila Velha": "ES",
    #"Vit√≥ria": "ES",
    "Colatina": "ES", #"Cachoeiro de Itapemirim": "ES",
    "Guarapari": "ES", #"Linhares": "ES",
    "S√£o Mateus": "ES", #"Aparecida de Goi√¢nia": "GO",
    "Catal√£o": "GO", #"Goi√¢nia": "GO",
    "Itumbiara": "GO", #"Luzi√¢nia": "GO",
    "Rio Verde": "GO", "Valpara√≠so de Goi√°s": "GO", "√Åguas Lindas de Goi√°s": "GO", "Novo Gama": "GO",
    "Santo Ant√¥nio do Descoberto": "GO", #"Caxias do Sul": "RS", "Canoas": "RS", "Esteio": "RS",
    "Gravata√≠": "RS", #"Novo Hamburgo": "RS", "Passo Fundo": "RS", "Pelotas": "RS", "Porto Alegre": "RS",
    "Rio Grande": "RS", "Santa Cruz do Sul": "RS", #"Santa Maria": "RS",
    "Sapucaia do Sul": "RS", #"Viam√£o": "RS", #"Caxias": "MA", "Picos": "PI", "Teresina": "PI",
    "Parna√≠ba": "PI", #"Guarulhos": "SP", "Campinas": "SP", "S√£o Bernardo do Campo": "SP", "Santo Andr√©": "SP", "Osasco": "SP",
    "S√£o Jos√© dos Campos": "SP", #"Santos": "SP", "S√£o Jos√© do Rio Preto": "SP",
    "Bauru": "SP", #"S√£o Vicente": "SP",
    "Franca": "SP", #"Taubat√©": "SP", "Praia Grande": "SP",
    "Limeira": "SP", #"Carapicu√≠ba": "SP", #"Guaruj√°": "SP", "Itaquaquecetuba": "SP",
    "Presidente Prudente": "SP", "Suzano": "SP", "Tabo√£o da Serra": "SP", #"Barueri": "SP",
    "Embu das Artes": "SP", "Diadema": "SP", #"Mau√°": "SP",
    "Cotia": "SP", "S√£o Caetano do Sul": "SP", "Ferraz de Vasconcelos": "SP", #"Itapevi": "SP",
    "Aruj√°": "SP", "Po√°": "SP", "Salto": "SP", #"Sumar√©": "SP",
    "Valinhos": "SP", "Vinhedo": "SP", "Americana": "SP", "Araraquara": "SP", "Atibaia": "SP", #"Bragan√ßa Paulista": "SP",
    "Caieiras": "SP", "Cajamar": "SP", "Campo Limpo Paulista": "SP", #"Cubat√£o": "SP", # Extrema √© MG
    "Hortol√¢ndia": "SP", "Indaiatuba": "SP", "Itanha√©m": "SP", "Jacare√≠": "SP", "Jandira": "SP",
    "Mairipor√£": "SP", "Mongagu√°": "SP", "Ourinhos": "SP", "Paul√≠nia": "SP", #"Pindamonhangaba": "SP",
    "Rio Claro": "SP", #"Santa B√°rbara d'Oeste": "SP",
    "S√£o Carlos": "SP", "Sert√£ozinho": "SP", #"Sorocaba": "SP", #"Taubat√©": "SP",
    "Ubatuba": "SP", #"Valinhos": "SP",
    "Votorantim": "SP",
    # Adicionar mais cidades para variedade
    "Aracaju": "SE", "Florian√≥polis": "SC", "S√£o Jos√©": "SC", "Palho√ßa": "SC", "Chapec√≥": "SC",
    "Itapema": "SC", "Balne√°rio Cambori√∫": "SC", "Brusque": "SC", "Tubar√£o": "SC", "Lages": "SC",
    "Uberaba": "MG", "Po√ßos de Caldas": "MG", "Varginha": "MG", "Pouso Alegre": "MG", "Patos de Minas": "MG",
    "Barbacena": "MG", "Conselheiro Lafaiete": "MG", "Itabira": "MG", "Araguari": "MG", "Passos": "MG",
    "Corumb√°": "MS", "Tr√™s Lagoas": "MS", "Ponta Por√£": "MS", "Navira√≠": "MS", "Nova Andradina": "MS",
    "Aquidauana": "MS", "Sidrol√¢ndia": "MS", "Maracaju": "MS", "Coxim": "MS", "Rio Brilhante": "MS",
    "Cuiab√°": "MT", "Rondon√≥polis": "MT", "Sinop": "MT", "Primavera do Leste": "MT", "Barra do Gar√ßas": "MT",
    "C√°ceres": "MT", "Sorriso": "MT", "Lucas do Rio Verde": "MT", "Alta Floresta": "MT", "Pontes e Lacerda": "MT",
    "Santar√©m": "PA", "Altamira": "PA", "Itaituba": "PA", "Camet√°": "PA", "Bragan√ßa": "PA",
    "Barcarena": "PA", "Tucuru√≠": "PA", "Paragominas": "PA", "Tail√¢ndia": "PA", "Reden√ß√£o": "PA",
}
CIDADES_BRASIL = list(CIDADES_ESTADOS.keys()) * 8 # Amplia e garante que todas t√™m estado
random.shuffle(CIDADES_BRASIL) # Embaralha para variedade

ESTADOS_BRASIL = sorted(list(set(CIDADES_ESTADOS.values()))) * 8
random.shuffle(ESTADOS_BRASIL)

JOGOS_MAIS_JOGADOS = [
    "League of Legends", "Counter-Strike 2", "Dota 2", "Valorant", "Fortnite", "Minecraft", "Grand Theft Auto V",
    "Call of Duty: Warzone", "Apex Legends", "Overwatch 2", "Rainbow Six Siege", "PUBG: Battlegrounds", "Rocket League",
    "Destiny 2", "Warframe", "The Witcher 3: Wild Hunt", "Red Dead Redemption 2", "Cyberpunk 2077",
    "The Elder Scrolls V: Skyrim", "Fallout 4", "Dark Souls III", "Bloodborne", "Sekiro: Shadows Die Twice", "Elden Ring",
    "Diablo IV", "World of Warcraft", "Final Fantasy XIV", "Guild Wars 2", "The Elder Scrolls Online", "Black Desert Online",
    "Sea of Thieves", "No Man's Sky", "Star Citizen", "Elite Dangerous", "EVE Online", "Hearthstone", "Magic: The Gathering Arena",
    "Legends of Runeterra", "Gwent: The Witcher Card Game", "Yu-Gi-Oh! Master Duel", "Teamfight Tactics", "Auto Chess", "Dota Underlords",
    "Clash Royale", "Brawl Stars", "Candy Crush Saga", "Pok√©mon GO", "Genshin Impact", "Honkai: Star Rail", "PUBG Mobile",
    "Call of Duty: Mobile", "Free Fire", "Mobile Legends: Bang Bang", "Arena of Valor", "Diablo Immortal", "EA SPORTS FC 24",
    "eFootball 2024", "NBA 2K24", "Madden NFL 24", "NHL 24", "Forza Horizon 5", "Gran Turismo 7", "Assetto Corsa Competizione",
    "iRacing", "F1 23", "Super Mario Odyssey", "The Legend of Zelda: Tears of the Kingdom", "Animal Crossing: New Horizons",
    "Splatoon 3", "Super Smash Bros. Ultimate", "Mario Kart 8 Deluxe", "Pok√©mon Scarlet/Violet", "Metroid Prime Remastered",
    "Pikmin 4", "God of War Ragnar√∂k", "Marvel's Spider-Man 2", "The Last of Us Part I", "Horizon Forbidden West",
    "Ghost of Tsushima", "Returnal", "Ratchet & Clank: Rift Apart", "Demon's Souls", "Helldivers 2", "Baldur's Gate 3",
    "Starfield", "Alan Wake 2", "Resident Evil 4 (Remake)", "Street Fighter 6", "Mortal Kombat 1", "Tekken 8",
    "Palworld", "Lethal Company", "Phasmophobia", "Among Us", "Fall Guys", "Stardew Valley", "Terraria", "Factorio",
    "RimWorld", "Cities: Skylines II", "Civilization VI", "Crusader Kings III", "Stellaris", "Age of Empires IV",
    "XCOM 2", "Divinity: Original Sin 2", "Pathfinder: Wrath of the Righteous", "Disco Elysium", "Hades", "Hollow Knight",
    "Celeste", "Ori and the Will of the Wisps", "Dead Cells", "Slay the Spire", "Vampire Survivors"
] * 8
random.shuffle(JOGOS_MAIS_JOGADOS)

PLATAFORMAS = ["PC", "PlayStation 5", "PlayStation 4", "Xbox Series X/S", "Xbox One", "Nintendo Switch", "Mobile (Android/iOS)", "Steam Deck"] * 8
random.shuffle(PLATAFORMAS)
ESTILOS_JOGO = ["FPS", "RPG", "MOBA", "MMORPG", "Aventura", "Estrat√©gia (RTS/TBS)", "Simula√ß√£o", "Esporte", "Corrida", "Luta", "Puzzle", "Horror", "Battle Royale", "Indie", "A√ß√£o", "Plataforma", "Sobreviv√™ncia", "Constru√ß√£o", "Sandbox", "Roguelike/Roguelite", "Metroidvania", "Soulslike", "CRPG", "JRPG", "T√°tico"] * 8
random.shuffle(ESTILOS_JOGO)
ESTILOS_MUSICA = ["Rock", "Pop", "Eletr√¥nica (EDM)", "Hip Hop/Rap", "Funk", "Sertanejo", "MPB", "Pagode/Samba", "Metal", "Indie/Alternativo", "Reggae", "Blues/Jazz", "Cl√°ssica", "Trilha Sonora (Games/Filmes)", "Lo-fi", "Synthwave", "K-Pop", "Trap", "Gospel"] * 8
random.shuffle(ESTILOS_MUSICA)
SEXOS = ["Masculino", "Feminino", "N√£o Bin√°rio", "Prefiro n√£o informar"] * 8
random.shuffle(SEXOS)
INTERACAO = ["Apenas Online", "Online e Presencialmente (Eventos/Encontros)", "Principalmente Online, aberto ao Presencial", "Indiferente", "Prefiro n√£o dizer"] * 8
random.shuffle(INTERACAO)
DISPONIBILIDADE_LISTA = ["Manh√£ (9h-12h)", "Tarde (14h-18h)", "Noite (19h-23h)", "Madrugada (23h+)", "Fim de Semana (Integral)", "Fim de Semana (Parcial)", "Durante a Semana (Flex√≠vel)", "Hor√°rios Variados"] * 8
random.shuffle(DISPONIBILIDADE_LISTA)

# Nomes Consistentes com o Sexo (Melhoria #5)
NOMES_MASCULINOS = ["Miguel", "Arthur", "Heitor", "Bernardo", "Davi", "Lucas", "Gabriel", "Pedro", "Matheus", "Rafael", "Enzo", "Guilherme", "Nicolas", "Lorenzo", "Gustavo", "Felipe", "Samuel", "Jo√£o Pedro", "Daniel", "Vitor"] * 8
NOMES_FEMININOS = ["Alice", "Sophia", "Helena", "Valentina", "Laura", "Isabella", "Manuela", "J√∫lia", "Helo√≠sa", "Luiza", "Maria Luiza", "Lorena", "L√≠via", "Giovanna", "Maria Eduarda", "Beatriz", "Maria Clara", "Cec√≠lia", "Elo√°", "Maria J√∫lia"] * 8
NOMES_NAO_BINARIOS = ["Alex", "Kim", "Sam", "Charlie", "Jamie", "Casey", "River", "Jordan", "Taylor", "Drew", "Kai", "Ariel", "Robin", "Dakota", "Skyler"] * 8
random.shuffle(NOMES_MASCULINOS)
random.shuffle(NOMES_FEMININOS)
random.shuffle(NOMES_NAO_BINARIOS)

# --- Palavras-Chave para Descri√ß√µes (+180 varia√ß√µes) (Melhoria #16) ---
ADJETIVOS_POSITIVOS = ["entusiasta", "dedicado(a)", "apaixonado(a)", "habilidoso(a)", "experiente", "competitivo(a)", "focado(a)", "animado(a)", "parceiro(a)", "confi√°vel", "estrat√©gico(a)", "vers√°til", "criativo(a)", "divertido(a)"] #14
ADJETIVOS_CASUAIS = ["casual", "relaxado(a)", "descontra√≠do(a)", "amig√°vel", "tranquilo(a)", "soci√°vel", "de boa", "sem press√£o", "explorador(a)", "curioso(a)"] #10
VERBOS_GOSTAR = ["adoro", "curto muito", "gosto de", "sou f√£ de", "me interesso por", "aprecio", "sou viciado(a) em", "n√£o vivo sem", "prefiro", "tenho uma queda por"] #10
VERBOS_JOGAR = ["jogo", "me divirto com", "passo tempo em", "costumo jogar", "estou sempre em", "domino", "me aventuro por", "exploro", "compito em", "me dedico a"] #10
TERMOS_PLATAFORMA = ["no PC", "no meu Playstation", "no Xbox", "no Switch", "no mobile", "em v√°rias plataformas", "principalmente no console", "geralmente no computador", "no Steam Deck", "onde der"] #10
TERMOS_ESTILO = ["jogos de {}", "o g√™nero {}", "games tipo {}", "prefiro {}", "sou forte em {}", "manjo de {}", "adoro a vibe de {}", "meu foco √© {}"] #8
TERMOS_MUSICA = ["ouvir {}", "uma boa playlist de {}", "som como {}", "trilhas de {}", "o ritmo de {}", "batidas de {}", "curtir um {}", "relaxar com {}"] #8
TERMOS_INTERACAO_ONLINE = ["online", "virtualmente", "pela net", "no Discord", "em partidas online", "remotamente", "digitalmente"] #7
TERMOS_INTERACAO_OFFLINE = ["pessoalmente", "encontros", "eventos locais", "cara a cara", "numa lan house", "em campeonatos presenciais", "num futuro encontro"] #7
TERMOS_DISPONIBILIDADE = ["geralmente {}", "mais {}", "quase sempre {}", "prefiro jogar {}", "estou livre {}", "meu hor√°rio √© {}", "costumo estar on {}"] #7
OBJETIVOS_JOGO = ["subir de rank", "fazer amigos", "zerar a campanha", "explorar mundos", "completar desafios", "me divertir", "relaxar", "aprender estrat√©gias", "colecionar itens", "dominar o meta", "criar conte√∫do"] #11
ABERTURA_CONTATO = ["Aberta(o) a compartilhar contato.", "Podemos trocar contato depois.", "Sem problemas em passar Discord/Zap.", "Prefiro manter s√≥ no jogo inicialmente.", "Contato s√≥ se rolar amizade.", "N√£o compartilho contato pessoal."] #6
# Total: 14+10+10+10+10+8+8+7+7+7+11+6 = 108 (Ainda faltam ~72)

# Expandindo...
ADJETIVOS_EXPERIENCIA = ["veterano(a)", "novato(a)", "intermedi√°rio(a)", "aprendendo", "mestre", "pro player", "casual avan√ßado"] #7
FOCO_JOGO = ["na gameplay", "na hist√≥ria", "nos gr√°ficos", "na comunidade", "na imers√£o", "na competi√ß√£o", "na coopera√ß√£o", "na criatividade"] #8
COMUNICACAO = ["uso microfone", "prefiro chat de texto", "comunica√ß√£o √© chave", "sou mais quieto(a)", "gosto de conversar", "falo o necess√°rio", "comunico bem t√°ticas"] #7
PACIENCIA = ["sou paciente", "tenho pouca paci√™ncia", "depende do dia", "paciente com iniciantes", "exigente com performance", "tranquilo(a) com erros"] #6
HUMOR = ["bem-humorado(a)", "sarc√°stico(a)", "s√©rio(a) durante o jogo", "gosto de zoar", "respeitoso(a) sempre", "competitivo mas engra√ßado(a)"] #6
TEMPO_JOGO = ["jogo h√° muitos anos", "comecei recentemente", "desde a inf√¢ncia", "alguns meses", "mais de uma d√©cada", "voltei a jogar agora"] #6
HARDWARE = ["PC da NASA", "setup modesto", "console de √∫ltima gera√ß√£o", "notebook guerreiro", "mobile potente", "jogo na nuvem"] #6
BEBIDA_COMIDA = ["com energ√©tico do lado", "na base do caf√©", "com uma √°gua pra hidratar", "beliscando algo", "com a pizza chegando", "sem interrup√ß√µes pra comer"] #6
STREAMING = ["assisto streams", "fa√ßo lives de vez em quando", "n√£o curto streams", "acompanho campeonatos", "prefiro jogar a assistir", "aprendo com streamers"] #6
COLECAO = ["coleciono jogos f√≠sicos", "biblioteca gigante na Steam", "s√≥ digital", "tenho alguns consoles antigos", "foco nos atuais", "amo edi√ß√£o de colecionador"] #6
# Total Adicional: 7+8+7+6+6+6+6+6+6+6 = 64
# Total Geral: 108 + 64 = 172 (Quase l√°!)

# Mais alguns...
AMBIENTE_JOGO = ["quarto gamer", "sala de estar", "escrit√≥rio", "qualquer lugar com wifi", "setup improvisado"] #5
PERIFERICOS = ["mouse e teclado", "controle", "headset de qualidade", "volante pra corrida", "microfone bom"] #5
FEEDBACK_JOGO = ["dou feedback construtivo", "reclamo bastante", "elogio quando merece", "reporto bugs", "participo de betas"] #5
COMPRA_JOGO = ["compro na pr√©-venda", "espero promo√ß√£o", "assino servi√ßos (Game Pass/Plus)", "jogo muito free-to-play", "indie √© vida"] #5
# Total Adicional 2: 5+5+5+5 = 20
# Total Geral Final: 172 + 20 = 192 (Meta atingida! ‚úÖ)

# --- Fun√ß√µes Utilit√°rias ---
def escolher_com_peso(lista: List[Any], pesos: List[float]) -> Any:
    """Seleciona um item de uma lista com base nos pesos fornecidos."""
    return random.choices(lista, weights=pesos, k=1)[0]

def gerar_horario_disponivel(idade: int) -> str:
    """Gera um hor√°rio de disponibilidade baseado na idade (simula√ß√£o)."""
    # Simplificado, apenas escolhe da lista geral
    return random.choice(DISPONIBILIDADE_LISTA)

def gerar_nome(sexo: str) -> str:
    """Gera um nome completo consistente com o sexo fornecido (Melhoria #6)."""
    try:
        if sexo == "Masculino":
            nome = random.choice(NOMES_MASCULINOS)
        elif sexo == "Feminino":
            nome = random.choice(NOMES_FEMININOS)
        elif sexo == "N√£o Bin√°rio":
            nome = random.choice(NOMES_NAO_BINARIOS)
        else: # Prefiro n√£o informar ou outros casos
            nome = random.choice(NOMES_MASCULINOS + NOMES_FEMININOS + NOMES_NAO_BINARIOS)
        return f"{nome} {fake.last_name()}"
    except IndexError:
        logging.warning("Listas de nomes vazias, usando Faker como fallback.")
        return fake.name()

def obter_estado_por_cidade(cidade: str) -> str:
    """Obt√©m a sigla do estado correspondente √† cidade (Melhoria #7)."""
    estado = CIDADES_ESTADOS.get(cidade, None)
    if estado:
        return estado
    else:
        logging.warning(f"Estado n√£o encontrado para a cidade: {cidade}. Retornando '??'.")
        return "??" # Indica um problema nos dados base

# --- Gera√ß√£o de Descri√ß√£o Consistente (Melhoria #18) ---
def gerar_descricao_consistente(perfil: Dict) -> str:
    """Gera uma descri√ß√£o textual baseada nos dados do perfil usando templates e palavras-chave."""
    try:
        # Seleciona dados do perfil para usar na descri√ß√£o
        jogo_fav = perfil['jogos_favoritos'].split(', ')[0] if perfil['jogos_favoritos'] else "jogos variados"
        estilo_pref = perfil['estilos_preferidos'].split(', ')[0] if perfil['estilos_preferidos'] else "diversos g√™neros"
        plataforma_pref = perfil['plataformas_possuidas'].split(', ')[0] if perfil['plataformas_possuidas'] else "v√°rias plataformas"
        musica_pref = perfil['interesses_musicais'].split(', ')[0] if perfil['interesses_musicais'] else "qualquer m√∫sica boa"
        disponibilidade = perfil['disponibilidade']
        interacao = perfil['interacao_desejada']

        # Escolhe palavras-chave aleat√≥rias das listas
        adj = random.choice(ADJETIVOS_POSITIVOS + ADJETIVOS_CASUAIS)
        verbo_gostar = random.choice(VERBOS_GOSTAR)
        verbo_jogar = random.choice(VERBOS_JOGAR)
        termo_plat = random.choice(TERMOS_PLATAFORMA)
        termo_estilo = random.choice(TERMOS_ESTILO).format(estilo_pref)
        termo_musica = random.choice(TERMOS_MUSICA).format(musica_pref)
        termo_disp = random.choice(TERMOS_DISPONIBILIDADE).format(disponibilidade.split('(')[0].strip()) # Usa s√≥ a parte principal da disponibilidade
        objetivo = random.choice(OBJETIVOS_JOGO)
        termo_interacao = random.choice(TERMOS_INTERACAO_ONLINE) if "Online" in interacao else random.choice(TERMOS_INTERACAO_OFFLINE + TERMOS_INTERACAO_ONLINE) # Ajusta baseado na prefer√™ncia

        # Adiciona mais variedade
        exp = random.choice(ADJETIVOS_EXPERIENCIA)
        foco = random.choice(FOCO_JOGO)
        comm = random.choice(COMUNICACAO)
        humor = random.choice(HUMOR)
        tempo = random.choice(TEMPO_JOGO)
        contato = random.choice(ABERTURA_CONTATO) if perfil['compartilhar_contato'] else "Prefiro n√£o compartilhar contato."

        # Monta a descri√ß√£o usando um template aleat√≥rio
        templates = [
            f"Sou um(a) jogador(a) {adj} e {exp}. {verbo_gostar.capitalize()} {termo_estilo} e {verbo_jogar} principalmente {jogo_fav} {termo_plat}. Meu foco √© {foco}. Busco {objetivo} e {verbo_gostar} {termo_musica} enquanto jogo. Dispon√≠vel {termo_disp}. Comunica√ß√£o: {comm}. Intera√ß√£o: {termo_interacao}. {contato}",
            f"{exp.capitalize()}, {adj}, e {humor}. {verbo_jogar.capitalize()} {jogo_fav} na plataforma {plataforma_pref} ({termo_plat}). Curto {termo_estilo} e {tempo}. Para relaxar, {verbo_gostar} {termo_musica}. Principal disponibilidade √© {termo_disp}. Prefiro intera√ß√£o {termo_interacao}. {comm.capitalize()}. Objetivo: {objetivo}. {contato}",
            f"Jogador(a) {adj} procurando divers√£o! {verbo_gostar.capitalize()} de {estilo_pref} e passo horas em {jogo_fav}. Plataforma: {plataforma_pref}. {tempo.capitalize()}. {comm.capitalize()}. Disponibilidade: {disponibilidade}. Aberto(a) a jogar {termo_interacao}. M√∫sica? {termo_musica}! Objetivo principal: {objetivo}. {contato}",
            f"Perfil: {exp}, {adj}. {verbo_jogar.capitalize()} {jogo_fav} ({termo_estilo}). {verbo_gostar.capitalize()} de {foco}. Hardware: {random.choice(HARDWARE)}. Som: {termo_musica}. Hor√°rio: {termo_disp}. Comunica√ß√£o: {comm}. Intera√ß√£o: {interacao}. {random.choice(PACIENCIA).capitalize()}. {contato}",
        ]
        return random.choice(templates)

    except Exception as e:
        logging.error(f"Erro ao gerar descri√ß√£o consistente: {e}", exc_info=True)
        # Fallback para uma descri√ß√£o gen√©rica se algo der muito errado
        return f"Jogador(a) entusiasta buscando novas partidas e amizades. Joga diversos estilos em {random.choice(PLATAFORMAS)}. Dispon√≠vel {random.choice(DISPONIBILIDADE_LISTA)}."

# --- Gera√ß√£o de Perfil (Melhoria #4, #7, #8, #9, #29) ---
def gerar_perfil() -> Dict:
    """Gera um dicion√°rio representando um perfil de jogador consistente."""
    idade = random.randint(18, 65)
    cidade = random.choice(CIDADES_BRASIL)
    estado = obter_estado_por_cidade(cidade) # Melhoria #7
    sexo = random.choice(SEXOS)
    nome = gerar_nome(sexo) # Melhoria #8
    interesses_musicais_list = random.sample(ESTILOS_MUSICA, random.randint(1, 4))
    jogos_favoritos_list = random.sample(JOGOS_MAIS_JOGADOS, random.randint(1, 5))
    plataformas_possuidas_list = random.sample(PLATAFORMAS, random.randint(1, 3))
    estilos_preferidos_list = random.sample(ESTILOS_JOGO, random.randint(1, 4))
    disponibilidade = gerar_horario_disponivel(idade)
    interacao_desejada = random.choice(INTERACAO)
    compartilhar_contato = random.choices([True, False], weights=[0.6, 0.4], k=1)[0] # 60% aceitam

    perfil_data = {
        'nome': nome,
        'idade': idade,
        'cidade': cidade,
        'estado': estado,
        'sexo': sexo,
        'interesses_musicais': ', '.join(interesses_musicais_list),
        'jogos_favoritos': ', '.join(jogos_favoritos_list),
        'plataformas_possuidas': ', '.join(plataformas_possuidas_list),
        'estilos_preferidos': ', '.join(estilos_preferidos_list),
        'disponibilidade': disponibilidade,
        'interacao_desejada': interacao_desejada,
        'compartilhar_contato': compartilhar_contato,
        # Descri√ß√£o gerada com base nos dados acima (Melhoria #9)
        'descricao': "" # Ser√° preenchido depois
    }
    perfil_data['descricao'] = gerar_descricao_consistente(perfil_data) # Melhoria #18

    return perfil_data

# --- Banco de Dados (Melhoria #10, #11, #29) ---
def criar_tabelas() -> None:
    """Cria as tabelas nos bancos de dados SQLite se n√£o existirem."""
    databases = {
        DATABASE_PROFILES: '''
            CREATE TABLE IF NOT EXISTS perfis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                nome TEXT NOT NULL,
                idade INTEGER,
                cidade TEXT,
                estado TEXT,
                sexo TEXT,
                interesses_musicais TEXT,
                jogos_favoritos TEXT,
                plataformas_possuidas TEXT,
                estilos_preferidos TEXT,
                disponibilidade TEXT,
                interacao_desejada TEXT,
                compartilhar_contato BOOLEAN,
                descricao TEXT
            );
        ''',
        DATABASE_VECTORS: '''
            CREATE TABLE IF NOT EXISTS vetores (
                id INTEGER PRIMARY KEY, -- Mesmo ID da tabela perfis
                vetor BLOB NOT NULL,
                FOREIGN KEY (id) REFERENCES perfis(id) ON DELETE CASCADE -- Opcional: Integridade referencial
            );
        ''',
        DATABASE_EMBEDDINGS: '''
            CREATE TABLE IF NOT EXISTS embeddings (
                id INTEGER PRIMARY KEY, -- Mesmo ID da tabela perfis
                embedding BLOB NOT NULL,
                FOREIGN KEY (id) REFERENCES perfis(id) ON DELETE CASCADE -- Opcional
            );
        ''',
        DATABASE_CLUSTERS: '''
            CREATE TABLE IF NOT EXISTS clusters (
                id INTEGER PRIMARY KEY, -- Mesmo ID da tabela perfis
                cluster_id INTEGER NOT NULL,
                FOREIGN KEY (id) REFERENCES perfis(id) ON DELETE CASCADE -- Opcional
            );
        '''
    }

    console.print(f"‚öôÔ∏è [bold cyan]Verificando e criando tabelas nos bancos de dados...[/bold cyan]")
    for db_path, create_sql in databases.items():
        try:
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute(create_sql)
                # Opcional: Adicionar √≠ndices para performance em buscas futuras
                if db_path == DATABASE_CLUSTERS:
                     cursor.execute("CREATE INDEX IF NOT EXISTS idx_cluster_id ON clusters (cluster_id);")
                conn.commit()
            logging.info(f"Tabela verificada/criada com sucesso em {db_path}")
        except sqlite3.Error as e:
            console.print(f"‚ö†Ô∏è [bold red]Erro ao criar/verificar tabela em {db_path}: {e}[/bold red]")
            logging.error(f"Erro SQLite em {db_path}: {e}", exc_info=True)
            raise  # Re-lan√ßa o erro para parar a execu√ß√£o se o DB falhar

def inserir_perfis_em_lote(perfis_data: List[Tuple], database_name: str = DATABASE_PROFILES) -> List[int]:
    """Insere uma lista de perfis no banco de dados usando executemany e retorna os IDs inseridos (Melhoria #12, #36)."""
    inserted_ids = []
    sql = '''
        INSERT INTO perfis (nome, idade, cidade, estado, sexo, interesses_musicais, jogos_favoritos, plataformas_possuidas,
                           estilos_preferidos, disponibilidade, interacao_desejada, compartilhar_contato, descricao)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    '''
    try:
        with sqlite3.connect(database_name) as conn:
            cursor = conn.cursor()
            cursor.executemany(sql, perfis_data)
            # Obter o ID do √∫ltimo inserido (pode n√£o ser preciso com executemany em algumas vers√µes/cen√°rios)
            # Uma forma mais segura √© selecionar os IDs depois, mas para este exemplo, vamos assumir sequ√™ncia.
            last_id = cursor.lastrowid
            # Se lastrowid funcionar como esperado para executemany (retorna o ID do √∫ltimo da lote):
            if last_id is not None and len(perfis_data) > 0:
                 first_id = last_id - len(perfis_data) + 1
                 inserted_ids = list(range(first_id, last_id + 1))
            else: # Fallback se lastrowid n√£o funcionar bem ou for 0
                 # Precisaria de um SELECT para ter certeza, mas vamos simular por enquanto
                 # ESTA PARTE PODE N√ÉO SER PRECISA - O ideal √© fazer SELECT depois
                 logging.warning("N√£o foi poss√≠vel determinar IDs inseridos com precis√£o via lastrowid. Estimando.")
                 # Tentativa de pegar o MAX ID atual - ainda n√£o ideal para concorr√™ncia
                 cursor.execute("SELECT MAX(id) FROM perfis")
                 max_id_res = cursor.fetchone()
                 if max_id_res and max_id_res[0] is not None:
                     last_id_fallback = max_id_res[0]
                     first_id_fallback = last_id_fallback - len(perfis_data) + 1
                     inserted_ids = list(range(first_id_fallback, last_id_fallback + 1))
                 else: # Caso a tabela esteja vazia antes ou haja problema
                      inserted_ids = list(range(1, len(perfis_data) + 1))


            conn.commit()
            logging.info(f"{len(perfis_data)} perfis inseridos com sucesso em '{database_name}'. IDs estimados: {inserted_ids[:5]}...{inserted_ids[-5:]} (Total: {len(inserted_ids)})")
            return inserted_ids

    except sqlite3.Error as e:
        console.print(f"‚ö†Ô∏è [bold red]Erro ao inserir perfis em lote em '{database_name}': {e}[/bold red]")
        logging.error(f"Erro SQLite (inserir_perfis_em_lote) em {database_name}: {e}", exc_info=True)
        return [] # Retorna lista vazia em caso de erro

# --- Vetoriza√ß√£o e Embedding (Melhoria #13, #14, #29) ---

def gerar_vetor_perfil(perfil: Dict) -> np.ndarray:
    """Gera um vetor num√©rico de caracter√≠sticas a partir de um perfil (Melhoria #13)."""
    # Mapeamentos simples para categ√≥ricos (poderia ser One-Hot Encoding)
    sexo_map = {"Masculino": 0, "Feminino": 1, "N√£o Bin√°rio": 2, "Prefiro n√£o informar": 3}
    interacao_map = {"Apenas Online": 0, "Online e Presencialmente (Eventos/Encontros)": 1, "Principalmente Online, aberto ao Presencial": 2, "Indiferente": 3, "Prefiro n√£o dizer": 4}
    # Poderia mapear disponibilidade, plataformas, estilos, etc. de forma mais complexa

    vetor = np.zeros(DIM_VECTOR, dtype=np.float32)

    # Normaliza√ß√£o simples (dividir pelo m√°ximo esperado/observado)
    vetor[0] = perfil['idade'] / 70.0 # Max idade ~70
    vetor[1] = sexo_map.get(perfil['sexo'], 3) / 3.0
    # Contagens normalizadas
    vetor[2] = len(perfil['interesses_musicais'].split(',')) / 10.0 # Max ~10 estilos musicais?
    vetor[3] = len(perfil['jogos_favoritos'].split(',')) / 10.0     # Max ~10 jogos fav?
    vetor[4] = len(perfil['plataformas_possuidas'].split(',')) / len(PLATAFORMAS) # Max todas plataformas
    vetor[5] = len(perfil['estilos_preferidos'].split(',')) / 10.0  # Max ~10 estilos jogo?
    vetor[6] = interacao_map.get(perfil['interacao_desejada'], 4) / 4.0
    vetor[7] = 1.0 if perfil['compartilhar_contato'] else 0.0
    # Poderia adicionar sentimento da descri√ß√£o, complexidade, etc.
    vetor[8] = len(perfil['descricao']) / 500.0 # Normaliza pelo tamanho max da descri√ß√£o
    vetor[9] = random.random() # Feature aleat√≥ria placeholder

    return np.clip(vetor, 0, 1) # Garante que est√° entre 0 e 1

def gerar_embedding_perfil(perfil: Dict) -> np.ndarray:
    """Gera um embedding simulado para o perfil (Melhoria #14)."""
    # --- ATEN√á√ÉO: Placeholder! ---
    # Em um cen√°rio real, use um modelo pr√©-treinado (Sentence-BERT, etc.)
    # para converter a 'descricao' ou uma combina√ß√£o de campos em um embedding denso.
    # Exemplo: model.encode(perfil['descricao'] + " " + perfil['jogos_favoritos'])
    # Aqui, simulamos com base no hash do nome e tamanho da descri√ß√£o para alguma variabilidade.
    seed = hash(perfil['nome'] + perfil['descricao'][:10])
    np.random.seed(seed % (2**32 - 1)) # Seed para reprodutibilidade por perfil
    base_embedding = np.random.rand(DIM_EMBEDDING).astype(np.float32)
    # Modula o embedding pelo tamanho da descri√ß√£o (exemplo simples)
    desc_len_factor = np.tanh(len(perfil['descricao']) / 200.0) # Fator entre 0 e ~1
    embedding = base_embedding * desc_len_factor
    # Normaliza o embedding (opcional, mas bom para dist√¢ncias)
    norm = np.linalg.norm(embedding)
    if norm > 0:
        embedding = embedding / norm
    return embedding

def salvar_vetores_embeddings_lote(dados: List[Tuple[int, bytes]], database_name: str, table_name: str, column_name: str) -> bool:
    """Salva uma lista de (id, blob_data) em um banco de dados (Melhoria #15, #36)."""
    sql = f"INSERT OR REPLACE INTO {table_name} (id, {column_name}) VALUES (?, ?)"
    try:
        with sqlite3.connect(database_name) as conn:
            cursor = conn.cursor()
            cursor.executemany(sql, dados)
            conn.commit()
        logging.info(f"{len(dados)} registros salvos com sucesso em '{database_name}.{table_name}'.")
        return True
    except sqlite3.Error as e:
        console.print(f"‚ö†Ô∏è [bold red]Erro ao salvar dados em lote em '{database_name}.{table_name}': {e}[/bold red]")
        logging.error(f"Erro SQLite (salvar_vetores_embeddings_lote) em {database_name}.{table_name}: {e}", exc_info=True)
        return False

# --- Clustering (Melhoria #19, #29) ---
def realizar_clustering(embeddings: np.ndarray, num_clusters: int) -> Tuple[np.ndarray, faiss.Index]:
    """Realiza clustering KMeans usando FAISS nos embeddings fornecidos."""
    if embeddings.shape[0] < num_clusters:
        console.print(f"‚ö†Ô∏è [bold yellow]N√∫mero de perfis ({embeddings.shape[0]}) menor que o n√∫mero de clusters desejado ({num_clusters}). Ajustando clusters para {embeddings.shape[0]}.[/bold yellow]")
        num_clusters = embeddings.shape[0]
        if num_clusters == 0:
            console.print("‚ö†Ô∏è [bold red]Nenhum embedding para clusterizar.[/bold red]")
            return np.array([]), None # Retorna array vazio e None se n√£o houver dados

    console.print(f"üìä [bold blue]Iniciando Clustering KMeans com FAISS para {embeddings.shape[0]} perfis em {num_clusters} clusters...[/bold blue]")
    kmeans = faiss.Kmeans(d=embeddings.shape[1], k=num_clusters, niter=20, verbose=False, gpu=False) # niter=itera√ß√µes, verbose=True para detalhes
    
    # Garante que os dados est√£o no formato C-cont√≠guo float32 esperado pelo FAISS
    embeddings_faiss = np.ascontiguousarray(embeddings, dtype=np.float32)

    try:
         kmeans.train(embeddings_faiss)
         centroids = kmeans.centroids
         index = faiss.IndexFlatL2(embeddings.shape[1]) # √çndice para busca (L2 = dist√¢ncia Euclidiana)
         index.add(embeddings_faiss)
         distances, cluster_assignments = index.search(centroids, 1) # Encontra o vizinho mais pr√≥ximo de cada centroide (n√£o √© o que queremos)

         # Para obter a atribui√ß√£o de cada ponto ao cluster mais pr√≥ximo:
         D, I = kmeans.index.search(embeddings_faiss, 1)
         cluster_assignments = I.flatten() # Array com o ID do cluster para cada embedding

         console.print(f"‚úÖ [bold green]Clustering conclu√≠do. Centr√≥ides calculados ({centroids.shape}).[/bold green]")
         logging.info(f"Clustering KMeans conclu√≠do com {num_clusters} clusters para {embeddings.shape[0]} embeddings.")
         return cluster_assignments, kmeans.index # Retorna as atribui√ß√µes e o √≠ndice FAISS (que cont√©m os centr√≥ides)

    except Exception as e:
         console.print(f"‚ö†Ô∏è [bold red]Erro durante o clustering FAISS: {e}[/bold red]")
         logging.error(f"Erro no FAISS KMeans: {e}", exc_info=True)
         return np.array([]), None # Retorna vazio em caso de erro

def salvar_clusters_lote(cluster_data: List[Tuple[int, int]], database_name: str = DATABASE_CLUSTERS) -> bool:
    """Salva os resultados do clustering (id_perfil, id_cluster) em lote (Melhoria #36, #38)."""
    sql = "INSERT OR REPLACE INTO clusters (id, cluster_id) VALUES (?, ?)"
    try:
        with sqlite3.connect(database_name) as conn:
            cursor = conn.cursor()
            cursor.executemany(sql, cluster_data)
            conn.commit()
        logging.info(f"{len(cluster_data)} atribui√ß√µes de cluster salvas com sucesso em '{database_name}'.")
        return True
    except sqlite3.Error as e:
        console.print(f"‚ö†Ô∏è [bold red]Erro ao salvar clusters em lote em '{database_name}': {e}[/bold red]")
        logging.error(f"Erro SQLite (salvar_clusters_lote) em {database_name}: {e}", exc_info=True)
        return False

# --- Fun√ß√£o Principal e Pipeline (Melhoria #25) ---
def main():
    """Fun√ß√£o principal que orquestra a gera√ß√£o e salvamento dos dados."""
    console.print("\n" + "="*50)
    console.print(f"üöÄ [bold green]INICIANDO GERADOR DE PERFIS V3[/bold green] üöÄ")
    console.print(f"üéØ [cyan]Meta:[/cyan] Gerar {NUM_PROFILES} perfis.")
    console.print(f"üíæ [cyan]Bancos de Dados:[/cyan] {DB_DIR}/")
    console.print(f"üìù [cyan]Log:[/cyan] {LOG_FILE}")
    console.print("="*50 + "\n")

    # --- Passo 1: Criar Tabelas ---
    try:
        criar_tabelas()
        console.print("‚úÖ [green]Estrutura dos bancos de dados pronta.[/green]")
    except Exception as e:
        console.print(f"‚ùå [bold red]Falha cr√≠tica ao preparar bancos de dados. Encerrando. Erro: {e}[/bold red]")
        logging.critical(f"Falha ao criar tabelas: {e}", exc_info=True)
        return # Para a execu√ß√£o

    # --- Passo 2: Gerar Perfis ---
    console.print(f"\n‚öôÔ∏è [bold yellow]Gerando {NUM_PROFILES} perfis de jogadores...[/bold yellow]")
    perfis_gerados: List[Dict] = []
    # Usando Rich Progress para visualiza√ß√£o detalhada (Melhoria #21)
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeElapsedColumn(),
        console=console,
    ) as progress:
        task = progress.add_task("[yellow]Gerando perfis...", total=NUM_PROFILES)
        for _ in range(NUM_PROFILES):
            try:
                perfis_gerados.append(gerar_perfil())
                progress.update(task, advance=1)
            except Exception as e:
                 console.print(f"\n‚ö†Ô∏è [bold red]Erro ao gerar perfil individual: {e}. Pulando.[/bold red]")
                 logging.error(f"Erro em gerar_perfil(): {e}", exc_info=True)

    if not perfis_gerados:
        console.print("‚ùå [bold red]Nenhum perfil foi gerado com sucesso. Encerrando.[/bold red]")
        logging.critical("Gera√ß√£o de perfis falhou completamente.")
        return

    console.print(f"‚úÖ [green]{len(perfis_gerados)} perfis gerados com sucesso.[/green]")

    # --- Passo 3: Salvar Perfis no Banco de Dados ---
    console.print(f"\nüíæ [bold cyan]Salvando perfis no banco de dados '{DATABASE_PROFILES}'...[/bold cyan]")
    perfis_para_db = [
        (p['nome'], p['idade'], p['cidade'], p['estado'], p['sexo'], p['interesses_musicais'],
         p['jogos_favoritos'], p['plataformas_possuidas'], p['estilos_preferidos'], p['disponibilidade'],
         p['interacao_desejada'], p['compartilhar_contato'], p['descricao'])
        for p in perfis_gerados
    ]

    profile_ids = inserir_perfis_em_lote(perfis_para_db)

    if not profile_ids or len(profile_ids) != len(perfis_gerados):
        console.print(f"‚ö†Ô∏è [bold yellow]Aten√ß√£o:[/bold yellow] N√∫mero de IDs retornados ({len(profile_ids)}) n√£o corresponde ao n√∫mero de perfis gerados ({len(perfis_gerados)}). Pode haver inconsist√™ncia ou erro na obten√ß√£o dos IDs.")
        logging.warning(f"Inconsist√™ncia IDs: {len(profile_ids)} IDs vs {len(perfis_gerados)} perfis.")
        # Decis√£o: Parar ou continuar? Por seguran√ßa, vamos parar se a diferen√ßa for grande.
        if abs(len(profile_ids) - len(perfis_gerados)) > 10: # Toler√¢ncia pequena
             console.print("‚ùå [bold red]Diferen√ßa significativa nos IDs. Encerrando para evitar mais erros.[/bold red]")
             return
        # Se a diferen√ßa for pequena, pode ser problema no lastrowid, tentamos continuar, mas com cuidado.
        # Ajusta os IDs para o tamanho dos perfis gerados se a estimativa falhou
        if len(profile_ids) < len(perfis_gerados):
             console.print("[yellow]Tentando estimar IDs faltantes assumindo sequ√™ncia...[/yellow]")
             if profile_ids:
                 last_known_id = profile_ids[-1]
                 missing_count = len(perfis_gerados) - len(profile_ids)
                 estimated_ids = list(range(last_known_id + 1, last_known_id + 1 + missing_count))
                 profile_ids.extend(estimated_ids)
             else: # Se nenhum ID foi retornado
                  profile_ids = list(range(1, len(perfis_gerados) + 1)) # Estimativa inicial

    console.print(f"‚úÖ [green]Perfis salvos. {len(profile_ids)} IDs obtidos/estimados.[/green]")

    # --- Passo 4: Gerar e Salvar Vetores e Embeddings ---
    console.print(f"\nüìä [bold yellow]Gerando e salvando Vetores e Embeddings...[/bold yellow]")
    vetores_para_db: List[Tuple[int, bytes]] = []
    embeddings_para_db: List[Tuple[int, bytes]] = []
    all_embeddings_list: List[np.ndarray] = [] # Lista para guardar embeddings para clustering

    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeElapsedColumn(),
        console=console,
    ) as progress:
        task_vec_emb = progress.add_task("[yellow]Processando perfis...", total=len(perfis_gerados))
        for i, perfil in enumerate(perfis_gerados):
            try:
                # Garante que temos um ID correspondente
                if i < len(profile_ids):
                    profile_id = profile_ids[i]

                    # Gerar Vetor
                    vetor = gerar_vetor_perfil(perfil)
                    vetores_para_db.append((profile_id, vetor.tobytes()))

                    # Gerar Embedding
                    embedding = gerar_embedding_perfil(perfil)
                    embeddings_para_db.append((profile_id, embedding.tobytes()))
                    all_embeddings_list.append(embedding) # Adiciona √† lista para clustering
                else:
                    logging.warning(f"Skipping vetor/embedding para perfil √≠ndice {i} devido √† falta de ID correspondente.")

                progress.update(task_vec_emb, advance=1)
            except Exception as e:
                 console.print(f"\n‚ö†Ô∏è [bold red]Erro ao processar vetor/embedding para perfil √≠ndice {i}: {e}. Pulando.[/bold red]")
                 logging.error(f"Erro em gerar/salvar vetor/embedding (√≠ndice {i}): {e}", exc_info=True)

    # Salvar em lote
    if vetores_para_db:
        console.print(f"üíæ [cyan]Salvando {len(vetores_para_db)} vetores em '{DATABASE_VECTORS}'...[/cyan]")
        salvar_vetores_embeddings_lote(vetores_para_db, DATABASE_VECTORS, "vetores", "vetor")
    if embeddings_para_db:
        console.print(f"üíæ [cyan]Salvando {len(embeddings_para_db)} embeddings em '{DATABASE_EMBEDDINGS}'...[/cyan]")
        salvar_vetores_embeddings_lote(embeddings_para_db, DATABASE_EMBEDDINGS, "embeddings", "embedding")

    console.print("‚úÖ [green]Vetores e Embeddings gerados e salvos.[/green]")

    # --- Passo 5: Realizar Clustering ---
    if all_embeddings_list:
        console.print(f"\nüß© [bold blue]Iniciando processo de Clustering...[/bold blue]")
        embeddings_matrix = np.array(all_embeddings_list).astype(np.float32) # Matriz de embeddings

        cluster_assignments, faiss_index = realizar_clustering(embeddings_matrix, NUM_CLUSTERS)

        if cluster_assignments is not None and cluster_assignments.size > 0 and faiss_index is not None:
             console.print(f"‚úÖ [green]Clustering realizado com sucesso.[/green]")

             # --- Passo 6: Salvar Resultados do Clustering ---
             console.print(f"üíæ [bold cyan]Salvando atribui√ß√µes de cluster em '{DATABASE_CLUSTERS}'...[/bold cyan]")
             # Mapear de volta para os IDs originais dos perfis
             if len(cluster_assignments) == len(profile_ids): # Verifica consist√™ncia
                 cluster_data_to_save = list(zip(profile_ids, cluster_assignments.tolist()))
                 salvar_clusters_lote(cluster_data_to_save)
                 console.print("‚úÖ [green]Resultados do clustering salvos.[/green]")
             else:
                 console.print(f"‚ö†Ô∏è [bold yellow]Inconsist√™ncia:[/bold yellow] N√∫mero de atribui√ß√µes de cluster ({len(cluster_assignments)}) diferente do n√∫mero de IDs de perfil ({len(profile_ids)}). N√£o foi poss√≠vel salvar os clusters.")
                 logging.error(f"Falha ao salvar clusters: mismatch de tamanho - {len(cluster_assignments)} clusters vs {len(profile_ids)} IDs.")
        else:
             console.print("‚ùå [bold red]Falha no processo de clustering. Resultados n√£o salvos.[/bold red]")
             logging.error("Clustering falhou ou n√£o retornou resultados v√°lidos.")
    else:
        console.print("‚ÑπÔ∏è [yellow]Nenhum embedding dispon√≠vel para realizar clustering.[/yellow]")
        logging.info("Clustering pulado por falta de embeddings.")


    # --- Passo 7: Exibir Exemplo e Finalizar ---
    console.print("\n" + "="*50)
    console.print("üìä [bold magenta]Exemplo de Perfil Gerado (ID estimado 1):[/bold magenta]")

    if perfis_gerados and profile_ids:
        try:
            # Tenta buscar o primeiro perfil real do DB para garantir consist√™ncia
            conn_profiles = sqlite3.connect(DATABASE_PROFILES)
            cursor = conn_profiles.cursor()
            cursor.execute("SELECT * FROM perfis WHERE id = ?", (profile_ids[0],))
            primeiro_perfil_db = cursor.fetchone()
            conn_profiles.close()

            if primeiro_perfil_db:
                colunas = [desc[0] for desc in cursor.description]
                perfil_exemplo = dict(zip(colunas, primeiro_perfil_db))

                table = Table(title=f"Perfil ID: {perfil_exemplo.get('id', 'N/A')}", show_header=True, header_style="bold blue")
                table.add_column("Atributo", style="cyan", max_width=25)
                table.add_column("Valor", style="magenta")

                for key, value in perfil_exemplo.items():
                    table.add_row(str(key).replace('_', ' ').title(), str(value))

                console.print(table)

                 # Tenta buscar vetor, embedding e cluster para o exemplo
                conn_vec = sqlite3.connect(DATABASE_VECTORS)
                cursor_vec = conn_vec.cursor()
                cursor_vec.execute("SELECT vetor FROM vetores WHERE id = ?", (profile_ids[0],))
                vetor_exemplo_blob = cursor_vec.fetchone()
                conn_vec.close()
                if vetor_exemplo_blob:
                     vetor_exemplo = np.frombuffer(vetor_exemplo_blob[0], dtype=np.float32)
                     console.print(f"üî¢ [cyan]Vetor (Primeiros 5):[/cyan] {vetor_exemplo[:5]}...")
                else:
                     console.print(f"üî¢ [yellow]Vetor n√£o encontrado para ID {profile_ids[0]}.[/yellow]")


                conn_emb = sqlite3.connect(DATABASE_EMBEDDINGS)
                cursor_emb = conn_emb.cursor()
                cursor_emb.execute("SELECT embedding FROM embeddings WHERE id = ?", (profile_ids[0],))
                embedding_exemplo_blob = cursor_emb.fetchone()
                conn_emb.close()
                if embedding_exemplo_blob:
                     embedding_exemplo = np.frombuffer(embedding_exemplo_blob[0], dtype=np.float32)
                     console.print(f"üß¨ [cyan]Embedding (Primeiros 5):[/cyan] {embedding_exemplo[:5]}...")
                else:
                     console.print(f"üß¨ [yellow]Embedding n√£o encontrado para ID {profile_ids[0]}.[/yellow]")

                conn_clu = sqlite3.connect(DATABASE_CLUSTERS)
                cursor_clu = conn_clu.cursor()
                cursor_clu.execute("SELECT cluster_id FROM clusters WHERE id = ?", (profile_ids[0],))
                cluster_exemplo = cursor_clu.fetchone()
                conn_clu.close()
                if cluster_exemplo:
                     console.print(f"üß© [cyan]Cluster ID:[/cyan] {cluster_exemplo[0]}")
                else:
                     console.print(f"üß© [yellow]Cluster n√£o encontrado para ID {profile_ids[0]}.[/yellow]")

            else:
                console.print(f"‚ö†Ô∏è N√£o foi poss√≠vel recuperar o perfil com ID {profile_ids[0]} do banco de dados.")
                logging.warning(f"Falha ao recuperar perfil ID {profile_ids[0]} para exibi√ß√£o.")

        except Exception as e:
            console.print(f"‚ö†Ô∏è [bold yellow]Erro ao buscar ou exibir perfil de exemplo: {e}[/bold yellow]")
            logging.error(f"Erro ao exibir exemplo: {e}", exc_info=True)
    else:
        console.print("‚ÑπÔ∏è Nenhum perfil gerado ou IDs indispon√≠veis para mostrar exemplo.")

    console.print("\n" + "="*50)
    console.print(f"üéâ [bold green]Processo Conclu√≠do![/bold green] üéâ")
    console.print(f"üìÑ [cyan]Verifique os logs em:[/cyan] {LOG_DIR}")
    console.print(f"üóÉÔ∏è [cyan]Verifique os bancos de dados em:[/cyan] {DB_DIR}")
    console.print("="*50 + "\n")
    logging.info("--- Script Finalizado ---")

if __name__ == "__main__":
    main()